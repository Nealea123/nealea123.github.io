---
title: "Robocon2023 & Robocon2024"
date: 2024-07-11
layout: post
categories: [Competition, Robot, Wheel Robot]
tags: [Competition, Robot, Wheel Robot]
---

## Introduction
Robocon is a popular Chinese robotics competition. It is an annual event that attracts many universities and young talents. Teams build robots to complete challenging tasks like racing, combat or cooperation. It promotes innovation, engineering skills and teamwork. The competition has a fun and exciting atmosphere, showing the great potential of China's robotics and young makers.


## Competition
### ROBOCON2023(National First Prize)
<html>
<body>
<div style="text-align: center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/ATvDr2iYxus?si=at3oAyKHRXBd5Bir" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>
</body>
</html>

### ROBOCON2024(Second Place of National First Prize)
<html>
<body>
<div style="text-align: center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/q6NofgzVdaM?si=UOOMZ-KN1lPF5J1J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>
</body>
</html>



<!-- ## Method
![hil hyper](/images/hil/hil_hyper.png) -->

<!-- The video shows a robot imitation learning experiment based on ROS/Gazebo. In the simulation environment, a robotic arm is operating a red and blue cube on the workbench. The "color_image" window in the top left corner displays the image information from the perspective of the robotic arm. This experiment aims to train the robot to complete cube manipulation tasks through imitation learning. -->

<!-- > A preprint of the paper is available at <kbd><a href="https://arxiv.org/abs/2404.12220" target="_blank" style="text-decoration: none; color: inherit;" >arXiv</a></kbd>
{: .prompt-tip } -->

<!-- , which is submitted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2024 -->

<!-- ## Motivation -->
<!-- ![Motivation](/images/slednav/sledinspir.bmp) -->


<!-- The figure presents a training process based on action block imitation learning.  In Step 1, it samples data from a demo dataset, including RGB images and joints information, to form an action sequence.  Step 2 involves inferring z through a transformer encoder with self - attention blocks, embedding joints and action sequences.  In Step 3, it uses a ResNet18 and transformer encoder and decoder to predict the action sequence, incorporating position embeddings and linear layers to output the predicted actions. -->

<!-- ![Physhical Curves](/images/arm/physical_curves.png) -->

<!-- The figure illustrates a Transformer - based testing process for predicting action sequences. ResNet18 extracts features from images of four cameras. These features, combined with sinusoidal position embeddings, are fed into a Transformer encoder. The encoder processes them and passes to a Transformer decoder, which generates the predicted action sequence with the aid of position embeddings. -->


<!-- ![Experiment](/images/slednav/sledtest.bmp)
**Experiment result**: tractor average speed **<font color="red">≈1m/s</font>**, trailer position error **<font color="red"><10cm</font>**, and trailer yaw angle error **<font color="red"><5.25°</font>** (calculated by motion capture system) -->